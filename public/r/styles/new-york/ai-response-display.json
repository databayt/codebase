{
  "$schema": "https://ui.shadcn.com/schema/registry-item.json",
  "name": "ai-response-display",
  "description": "Display AI responses with markdown and code highlighting",
  "type": "registry:atom",
  "registryDependencies": [
    "card"
  ],
  "files": [
    {
      "path": "components/atom/ai-response-display.tsx",
      "content": "'use client';\n\nimport { useState, useEffect, useRef } from 'react';\nimport { Response } from './response';\nimport { Reasoning, ReasoningTrigger, ReasoningContent } from './reasoning';\nimport { cn } from '@/lib/utils';\n\ninterface AIResponseDisplayProps {\n  response?: string;\n  reasoning?: string;\n  isStreaming?: boolean;\n  className?: string;\n  showReasoning?: boolean;\n  streamDelay?: number;\n  onStreamComplete?: () => void;\n}\n\nexport function AIResponseDisplay({\n  response = '',\n  reasoning = '',\n  isStreaming = false,\n  className,\n  showReasoning = true,\n  streamDelay = 8, // Faster for letter-by-letter effect\n  onStreamComplete,\n}: AIResponseDisplayProps) {\n  const [duration] = useState(Math.floor(Math.random() * 3) + 2); // Simulate 2-5 seconds thinking\n  const [responseStatus, setResponseStatus] = useState<'streaming' | 'done' | 'failed' | 'rejected' | null>(null);\n  const containerRef = useRef<HTMLDivElement>(null);\n\n  useEffect(() => {\n    if (isStreaming && response) {\n      setResponseStatus('streaming');\n    } else if (!isStreaming && response) {\n      // Delay setting to 'done' to ensure streaming completes\n      const timer = setTimeout(() => {\n        setResponseStatus('done');\n        onStreamComplete?.();\n      }, 100);\n      return () => clearTimeout(timer);\n    }\n  }, [isStreaming, response, onStreamComplete]);\n\n  return (\n    <div className={cn('space-y-4', className)}>\n      {showReasoning && reasoning && (\n        <Reasoning\n          isStreaming={isStreaming}\n          duration={duration}\n          defaultOpen={isStreaming}\n        >\n          <ReasoningTrigger />\n          <ReasoningContent>{reasoning}</ReasoningContent>\n        </Reasoning>\n      )}\n\n      {response && (\n        <div className=\"p-4 rounded-lg border bg-card\" ref={containerRef}>\n          <Response\n            status={responseStatus}\n            streamDelay={streamDelay}\n            onStatusChange={(status) => {\n              setResponseStatus(status);\n              if (status === 'done') {\n                onStreamComplete?.();\n              }\n            }}\n          >\n            {response}\n          </Response>\n        </div>\n      )}\n    </div>\n  );\n}\n\n// Enhanced hook for using AI responses with streaming\nexport function useAIResponse() {\n  const [response, setResponse] = useState('');\n  const [reasoning, setReasoning] = useState('');\n  const [isStreaming, setIsStreaming] = useState(false);\n  const [status, setStatus] = useState<'idle' | 'streaming' | 'done' | 'failed'>('idle');\n\n  const generateResponse = async (\n    prompt: string,\n    options?: {\n      includeReasoning?: boolean;\n      simulateStream?: boolean;\n      onChunk?: (chunk: string) => void;\n    }\n  ) => {\n    setStatus('streaming');\n    setIsStreaming(true);\n    setResponse(''); // Clear previous response\n\n    // Simulate AI reasoning\n    if (options?.includeReasoning) {\n      setReasoning(`## Analysis Process\n\n1. **Understanding the request**: Parsing the user's input to identify key requirements\n2. **Data extraction**: Identifying relevant information from the context\n3. **Pattern matching**: Applying appropriate patterns and best practices\n4. **Validation**: Ensuring the response meets quality standards\n5. **Optimization**: Refining the output for clarity and usefulness`);\n    }\n\n    try {\n      // Simulate streaming response\n      const fullResponse = `## AI Generated Response\n\nBased on the analysis, here's the generated content tailored to your requirements:\n\n- **Key Point 1**: Detailed explanation of the first important aspect\n- **Key Point 2**: Additional insights and recommendations\n- **Key Point 3**: Actionable steps and best practices\n\n### Next Steps\n1. Review the generated content\n2. Make any necessary adjustments\n3. Implement the recommendations\n\n### Summary\nThe process has been completed successfully with all requirements met.`;\n\n      if (options?.simulateStream) {\n        // Simulate chunked streaming\n        const words = fullResponse.split(' ');\n        let currentResponse = '';\n\n        for (let i = 0; i < words.length; i++) {\n          await new Promise(resolve => setTimeout(resolve, 50)); // Delay between words\n          currentResponse += (i === 0 ? '' : ' ') + words[i];\n          setResponse(currentResponse);\n          options?.onChunk?.(words[i]);\n        }\n      } else {\n        // Set full response at once\n        await new Promise(resolve => setTimeout(resolve, 1500));\n        setResponse(fullResponse);\n      }\n\n      setStatus('done');\n    } catch (error) {\n      setStatus('failed');\n      setResponse('Failed to generate response. Please try again.');\n    } finally {\n      setIsStreaming(false);\n    }\n  };\n\n  const reset = () => {\n    setResponse('');\n    setReasoning('');\n    setIsStreaming(false);\n    setStatus('idle');\n  };\n\n  return {\n    response,\n    reasoning,\n    isStreaming,\n    status,\n    generateResponse,\n    setResponse,\n    setReasoning,\n    reset,\n  };\n}",
      "type": "registry:component",
      "target": "components/ai-response-display.tsx"
    }
  ],
  "categories": [
    "ai",
    "display"
  ]
}